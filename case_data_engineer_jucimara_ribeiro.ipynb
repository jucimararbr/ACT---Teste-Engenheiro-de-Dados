{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Xa16vjfUcEmD",
        "PF_pECV0ejVb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA1XONLHLlzd",
        "outputId": "fc5ac918-6aee-4520-8221-72cff82fed80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#________________________________________________________________________________________\n",
        "# import spark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "job_name = 'case_data_engineer'\n",
        "spark = SparkSession.builder.appName(job_name).getOrCreate()"
      ],
      "metadata": {
        "id": "h-4XOAhlLrr6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1: Manipulação de Dados"
      ],
      "metadata": {
        "id": "Xa16vjfUcEmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do DataFrame\n"
      ],
      "metadata": {
        "id": "I_l7a2mxcLOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(\n",
        "    [\n",
        "        (\"Alice\", 34, \"Data Scientist\"),\n",
        "        (\"Bob\", 45, \"Data Engineer\"),\n",
        "        (\"Cathy\", 29, \"Data Analyst\"),\n",
        "        (\"David\", 35, \"Data Scientist\"),\n",
        "    ],\n",
        "    [\"Name\", \"Age\", \"Occupation\"]\n",
        ")\n",
        "\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NufTy5sKL3gS",
        "outputId": "e28d2884-320f-4a3e-b763-3b893893caf6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            " |-- Occupation: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtragem e Seleção\n",
        "\n",
        "Selecione apenas as colunas \"Name\" e \"Age\" do DataFrame criado."
      ],
      "metadata": {
        "id": "lojzu32RcyKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('Name', 'Age').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdYsunemdAJR",
        "outputId": "611edb54-007c-40fa-9d94-44d67bc4ae3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "|Name |Age|\n",
            "+-----+---+\n",
            "|Alice|34 |\n",
            "|Bob  |45 |\n",
            "|Cathy|29 |\n",
            "|David|35 |\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtre as linhas onde a \"Age\" é maior que 30."
      ],
      "metadata": {
        "id": "dshCgkIvdJUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('Name', 'Age').filter('Age > 30').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VxJr9FEdKOA",
        "outputId": "7da34916-e7fa-4b05-a016-706344f8f214"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "|Name |Age|\n",
            "+-----+---+\n",
            "|Alice|34 |\n",
            "|Bob  |45 |\n",
            "|David|35 |\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamento e Agregação\n",
        "\n",
        "Agrupe os dados pelo campo \"Occupation\" e calcule a média de \"Age\" para cada grupo."
      ],
      "metadata": {
        "id": "ALle62RldYSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_agg = df.groupBy('Occupation').agg(F.avg('Age').alias('avgAge'))\n",
        "df_agg.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiZmpJc7dekg",
        "outputId": "21040f9b-9a00-4fa5-ae10-786a02205455"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------+\n",
            "|Occupation    |avgAge|\n",
            "+--------------+------+\n",
            "|Data Scientist|34.5  |\n",
            "|Data Engineer |45.0  |\n",
            "|Data Analyst  |29.0  |\n",
            "+--------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordenação\n",
        "\n",
        "Ordene o DataFrame resultante da questão anterior pela média de \"Age\" em ordem decrescente."
      ],
      "metadata": {
        "id": "LhFawZjTd4tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_agg.sort(F.desc('avgAge')).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5XrhPIMeDwq",
        "outputId": "0f3e3bdf-ceb4-4aab-fadb-710f5e2f0cec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------+\n",
            "|Occupation    |avgAge|\n",
            "+--------------+------+\n",
            "|Data Engineer |45.0  |\n",
            "|Data Scientist|34.5  |\n",
            "|Data Analyst  |29.0  |\n",
            "+--------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 2: Funções Avançadas"
      ],
      "metadata": {
        "id": "PF_pECV0ejVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando a UDF que converte idades em categorias e aplicando ao DataFrame:"
      ],
      "metadata": {
        "id": "3M79J2IsepBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def age_category(age):\n",
        "    result = None\n",
        "    if age is not None:\n",
        "        if age < 30:\n",
        "            return \"Jovem\"\n",
        "        elif age >= 30 & age <= 40:\n",
        "            return \"Adulto\"\n",
        "        elif age > 40:\n",
        "            return \"Senior\"\n",
        "\n",
        "df_get_age_category = F.udf(age_category, StringType())\n",
        "df = df.withColumn('ageCategory', df_get_age_category('Age'))\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JJu5ki9e2l5",
        "outputId": "cee0a97c-d2b0-4f59-fbd5-00276ccfc6ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+--------------+-----------+\n",
            "|Name |Age|Occupation    |ageCategory|\n",
            "+-----+---+--------------+-----------+\n",
            "|Alice|34 |Data Scientist|Adulto     |\n",
            "|Bob  |45 |Data Engineer |Adulto     |\n",
            "|Cathy|29 |Data Analyst  |Jovem      |\n",
            "|David|35 |Data Scientist|Adulto     |\n",
            "+-----+---+--------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funções de Janela\n",
        "\n",
        "Use funções de janela para adicionar uma coluna que mostre a diferença de idade entre cada indivíduo e a média de idade do seu \"Occupation\"."
      ],
      "metadata": {
        "id": "Ac0eFI05fFHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpec = Window.partitionBy(\"Occupation\")\n",
        "df = df.withColumn(\"avgAgeOccupation\", F.avg(\"Age\").over(windowSpec))\n",
        "df = df.withColumn(\"ageDifference\", (F.col(\"Age\") - F.col(\"avgAgeOccupation\")))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qFFm1G0fOQp",
        "outputId": "13e8867f-7e65-4f19-b38a-2f3eeb1b1998"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+--------------+-----------+----------------+-------------+\n",
            "| Name|Age|    Occupation|ageCategory|avgAgeOccupation|ageDifference|\n",
            "+-----+---+--------------+-----------+----------------+-------------+\n",
            "|Cathy| 29|  Data Analyst|      Jovem|            29.0|          0.0|\n",
            "|  Bob| 45| Data Engineer|     Adulto|            45.0|          0.0|\n",
            "|Alice| 34|Data Scientist|     Adulto|            34.5|         -0.5|\n",
            "|David| 35|Data Scientist|     Adulto|            34.5|          0.5|\n",
            "+-----+---+--------------+-----------+----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 3: Performance e Otimização"
      ],
      "metadata": {
        "id": "1ols6C5DfyST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Particionamento\n",
        "\n",
        "Explique como o particionamento pode ser usado para melhorar a performance em operações de leitura e escrita de dados em PySpark. Dê um exemplo de código que particiona um DataFrame por uma coluna específica."
      ],
      "metadata": {
        "id": "SdY8sDQ7f2JB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "      Pode ser utilizado para organizar os dados em partes menores com um ou mais campos.\n",
        "      O particionamento permite o Spark processar os dados mais rapido acessando apenas as partiçoes necessarias na hora em que houve a consulta."
      ],
      "metadata": {
        "id": "zqMrwXizrR3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv = spark.read.csv(\"sample_data/ibge_nomes.csv\", header=True, inferSchema=True)\n",
        "df_csv.show()\n",
        "output_path = \"result/ibge_nome/output/particionado\"\n",
        "df_csv.write.partitionBy(\"sexo\").parquet(output_path)\n",
        "spark.read.parquet(output_path).filter(\"sexo = 'F'\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9gYyjKFoI7g",
        "outputId": "db48a24d-c51d-43bc-97d8-6e23bd14a97d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+-------+----+----+\n",
            "|     nome|regiao|   freq|rank|sexo|\n",
            "+---------+------+-------+----+----+\n",
            "|     JOSE|     0|5732508|   1|   M|\n",
            "|     JOAO|     0|2971935|   2|   M|\n",
            "|  ANTONIO|     0|2567494|   3|   M|\n",
            "|FRANCISCO|     0|1765197|   4|   M|\n",
            "|   CARLOS|     0|1483121|   5|   M|\n",
            "|    PAULO|     0|1417907|   6|   M|\n",
            "|    PEDRO|     0|1213557|   7|   M|\n",
            "|    LUCAS|     0|1116818|   8|   M|\n",
            "|     LUIZ|     0|1102927|   9|   M|\n",
            "|   MARCOS|     0|1101126|  10|   M|\n",
            "|     LUIS|     0| 931530|  11|   M|\n",
            "|  GABRIEL|     0| 922744|  12|   M|\n",
            "|   RAFAEL|     0| 814709|  13|   M|\n",
            "|   DANIEL|     0| 706527|  14|   M|\n",
            "|  MARCELO|     0| 690098|  15|   M|\n",
            "|    BRUNO|     0| 663271|  16|   M|\n",
            "|  EDUARDO|     0| 628539|  17|   M|\n",
            "|   FELIPE|     0| 615924|  18|   M|\n",
            "| RAIMUNDO|     0| 611174|  19|   M|\n",
            "|  RODRIGO|     0| 598825|  20|   M|\n",
            "+---------+------+-------+----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Broadcast Join\n",
        "\n",
        "Descreva o conceito de Broadcast Join em PySpark e como ele pode ser usado para otimizar operações de join. Implemente um exemplo de Broadcast Join entre dois DataFrames."
      ],
      "metadata": {
        "id": "JVvhKG2Cf4_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "      O Broadcast Join é uma técnica de otimização em PySpark usada quando realizamos operações de join entre dois DataFrames de tamanhos muito diferentes.\n",
        "      Em um Broadcast Join, o Spark transmite o DataFrame menor para todos os nós do cluster, de forma que cada nó possa executar o join localmente, sem precisar redistribuir os dados grandes entre os nós.\n",
        "      Só é interessante utilizar esta funcionalidade quando o dataframe menor couber na memória de cada nó.\n"
      ],
      "metadata": {
        "id": "iraGyeZPsm5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# criando os DataFrame\n",
        "df_large = spark.createDataFrame(\n",
        "    [\n",
        "        (\"Alice\", 34, \"Data Scientist\", 1),\n",
        "        (\"Bob\", 45, \"Data Engineer\", 2),\n",
        "        (\"Cathy\", 29, \"Data Analyst\", 3),\n",
        "        (\"David\", 35, \"Data Scientist\", 4),\n",
        "        (\"Jucimara\", 30, \"Data Engineer\", 1),\n",
        "        (\"João\", 25, \"Data Engineer\", 4),\n",
        "    ],\n",
        "    [\"Name\", \"Age\", \"Occupation\", \"idCity\"]\n",
        ")\n",
        "\n",
        "df_small = spark.createDataFrame(\n",
        "    [\n",
        "        (1, \"Buenópolis\"),\n",
        "        (2, \"Curvelo\"),\n",
        "        (3, \"Montes Claros\")\n",
        "    ],\n",
        "    [\"idCity\", \"City\"]\n",
        ")\n",
        "\n",
        "df_large.show()\n",
        "df_small.show()\n",
        "\n",
        "df_joined = df_large.join(F.broadcast(df_small), [\"idCity\"], \"left\")\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL9pbbB8snHg",
        "outputId": "38b3329e-28af-496c-f910-9d51d6686b46"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+--------------+------+\n",
            "|    Name|Age|    Occupation|idCity|\n",
            "+--------+---+--------------+------+\n",
            "|   Alice| 34|Data Scientist|     1|\n",
            "|     Bob| 45| Data Engineer|     2|\n",
            "|   Cathy| 29|  Data Analyst|     3|\n",
            "|   David| 35|Data Scientist|     4|\n",
            "|Jucimara| 30| Data Engineer|     1|\n",
            "|    João| 25| Data Engineer|     4|\n",
            "+--------+---+--------------+------+\n",
            "\n",
            "+------+-------------+\n",
            "|idCity|         City|\n",
            "+------+-------------+\n",
            "|     1|   Buenópolis|\n",
            "|     2|      Curvelo|\n",
            "|     3|Montes Claros|\n",
            "+------+-------------+\n",
            "\n",
            "+------+--------+---+--------------+-------------+\n",
            "|idCity|    Name|Age|    Occupation|         City|\n",
            "+------+--------+---+--------------+-------------+\n",
            "|     1|   Alice| 34|Data Scientist|   Buenópolis|\n",
            "|     2|     Bob| 45| Data Engineer|      Curvelo|\n",
            "|     3|   Cathy| 29|  Data Analyst|Montes Claros|\n",
            "|     4|   David| 35|Data Scientist|         NULL|\n",
            "|     1|Jucimara| 30| Data Engineer|   Buenópolis|\n",
            "|     4|    João| 25| Data Engineer|         NULL|\n",
            "+------+--------+---+--------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 4: Integração com Outras Tecnologias"
      ],
      "metadata": {
        "id": "YYWIyoqCgBJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leitura e Escrita de Dados\n",
        "\n",
        "Demonstre como ler dados de um arquivo CSV e escrever o resultado em um formato Parquet."
      ],
      "metadata": {
        "id": "nl18RopJgCda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv = spark.read.csv(\"sample_data/ibge-fem-10000.csv\", header=True, inferSchema=True)\n",
        "df_csv.show()\n",
        "output_path = \"result/ibge-fem/output/ibge-fem.parquet\"\n",
        "df_csv.write.parquet(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVJAv8bCgzT4",
        "outputId": "c1abdbed-bf47-4956-ce78-c81f4a9f3659"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+--------+----+----+\n",
            "|     nome|regiao|    freq|rank|sexo|\n",
            "+---------+------+--------+----+----+\n",
            "|    MARIA|     0|11694738|   1|   F|\n",
            "|      ANA|     0| 3079729|   2|   F|\n",
            "|FRANCISCA|     0|  721637|   3|   F|\n",
            "|  ANTONIA|     0|  588783|   4|   F|\n",
            "|  ADRIANA|     0|  565621|   5|   F|\n",
            "|  JULIANA|     0|  562589|   6|   F|\n",
            "|   MARCIA|     0|  551855|   7|   F|\n",
            "| FERNANDA|     0|  531607|   8|   F|\n",
            "| PATRICIA|     0|  529446|   9|   F|\n",
            "|    ALINE|     0|  509869|  10|   F|\n",
            "|   SANDRA|     0|  479230|  11|   F|\n",
            "|   CAMILA|     0|  469851|  12|   F|\n",
            "|   AMANDA|     0|  464624|  13|   F|\n",
            "|    BRUNA|     0|  460770|  14|   F|\n",
            "|  JESSICA|     0|  456472|  15|   F|\n",
            "|  LETICIA|     0|  434056|  16|   F|\n",
            "|    JULIA|     0|  430067|  17|   F|\n",
            "|  LUCIANA|     0|  429769|  18|   F|\n",
            "|  VANESSA|     0|  417512|  19|   F|\n",
            "|  MARIANA|     0|  381778|  20|   F|\n",
            "+---------+------+--------+----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integração com Hadoop\n",
        "\n",
        "Explique como PySpark se integra com o Hadoop HDFS para leitura e escrita de dados. Dê um exemplo de código que leia um arquivo do HDFS e salve o resultado de volta no HDFS."
      ],
      "metadata": {
        "id": "xGFg_mgzgGaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "     o Spark é reponsavel por ler os dados direto no HDFS, esta leitura é distribuida entre os nós diponiveis no cluster, garantindo perfomance.\n",
        "     Semelhante ocorre o processo de escrita, onde o Spark divide e distrui entre os nós, permitindo alta velocidade de escrita."
      ],
      "metadata": {
        "id": "Uoxg2XE_kGtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_hdfs = SparkSession.builder.appName(job_name).config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000/tmp/sample\").getOrCreate()"
      ],
      "metadata": {
        "id": "TbEKmdh4l1aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hdfs_path = \"hdfs://namenode_host:port/user/hadoop/dados.csv\"\n",
        "\n",
        "df_hdfs = spark.read.csv(hdfs_path, header=True, inferSchema=True)\n",
        "\n",
        "df_hdfs.show()"
      ],
      "metadata": {
        "id": "TK1PDg5amfzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"hdfs://namenode_host:port/user/hadoop/output/dados_filtrados.parquet\"\n",
        "\n",
        "df_hdfs.write.parquet(output_path)"
      ],
      "metadata": {
        "id": "aBdyYREWmxyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 5: Problema de Caso"
      ],
      "metadata": {
        "id": "4SonnNj7gL9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processamento de Logs\n",
        "\n",
        "Considere que você tem um grande arquivo de log com as seguintes colunas: \"timestamp\", \"user_id\", \"action\". Cada linha representa uma ação realizada por um usuário em um determinado momento."
      ],
      "metadata": {
        "id": "d3z1bTUEgQdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Funções auxiliares para gerar dados\n",
        "def generate_timestamp(start, end):\n",
        "    \"\"\"Gera um timestamp aleatório entre a data de início e fim.\"\"\"\n",
        "    return start + timedelta(seconds=random.randint(0, int((end - start).total_seconds())))\n",
        "\n",
        "def generate_user_id():\n",
        "    \"\"\"Gera um user_id aleatório entre 1000 e 1150.\"\"\"\n",
        "    return random.randint(1000, 1150)\n",
        "\n",
        "def generate_action():\n",
        "    \"\"\"Gera uma ação aleatória realizada pelo usuário.\"\"\"\n",
        "    actions = [\"login\", \"logout\", \"view_page\", \"click_ad\"]\n",
        "    return random.choice(actions)\n",
        "\n",
        "# Configurações\n",
        "num_lines = 6001\n",
        "start_date = datetime(2023, 1, 1)\n",
        "end_date = datetime(2024, 8, 21)\n",
        "\n",
        "# Caminho do arquivo de log\n",
        "log_file = \"sample_data/user_activity_log.csv\"\n",
        "\n",
        "# Gerando o arquivo de log\n",
        "with open(log_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"timestamp\", \"user_id\", \"action\"])  # Cabeçalhos\n",
        "\n",
        "    for _ in range(num_lines):\n",
        "        timestamp = generate_timestamp(start_date, end_date)\n",
        "        user_id = generate_user_id()\n",
        "        action = generate_action()\n",
        "        writer.writerow([timestamp, user_id, action])\n",
        "\n",
        "print(f\"Arquivo de log '{log_file}' gerado com {num_lines} linhas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-81PY5V9uHkT",
        "outputId": "acfb7c73-3f46-4cc5-934c-0a8f903a7346"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo de log 'sample_data/user_activity_log.csv' gerado com 6001 linhas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregue o arquivo de log em um DataFrame."
      ],
      "metadata": {
        "id": "6hmIZ36qgXq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_log = spark.read.csv(log_file, header=True, inferSchema=True)\n",
        "df_log.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bnyaYunwPRN",
        "outputId": "7e32a679-71a9-4d2c-db4c-937a4e8ff995"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------+---------+\n",
            "|          timestamp|user_id|   action|\n",
            "+-------------------+-------+---------+\n",
            "|2023-11-19 00:03:30|   1064| click_ad|\n",
            "|2023-02-18 11:37:18|   1040|    login|\n",
            "|2023-12-28 17:10:26|   1001|    login|\n",
            "|2024-02-27 00:14:49|   1010|view_page|\n",
            "|2024-06-25 08:54:26|   1017|   logout|\n",
            "|2023-12-18 08:20:31|   1046| click_ad|\n",
            "|2023-04-15 18:17:19|   1034|view_page|\n",
            "|2024-03-21 03:47:06|   1118|view_page|\n",
            "|2023-06-29 16:41:40|   1087|   logout|\n",
            "|2024-06-06 20:49:41|   1116|view_page|\n",
            "|2023-06-02 20:53:39|   1022| click_ad|\n",
            "|2023-06-03 00:36:47|   1023|    login|\n",
            "|2023-11-20 03:05:44|   1057|    login|\n",
            "|2023-07-28 00:20:22|   1142|view_page|\n",
            "|2023-05-08 13:10:30|   1071| click_ad|\n",
            "|2024-08-20 21:33:09|   1145|   logout|\n",
            "|2023-03-07 09:09:37|   1145| click_ad|\n",
            "|2023-08-17 03:02:17|   1060|view_page|\n",
            "|2024-04-03 19:26:13|   1041| click_ad|\n",
            "|2024-05-21 06:30:14|   1027|    login|\n",
            "+-------------------+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conte o número de ações realizadas por cada usuário."
      ],
      "metadata": {
        "id": "kRod4QMAgZis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = df_log.groupBy('user_id').agg(F.count('action').alias('qtdAction'))\n",
        "df_result.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt_tMI9o71Pt",
        "outputId": "28b8e016-e714-48a2-a581-ae7fd12459bf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|user_id|qtdAction|\n",
            "+-------+---------+\n",
            "|1088   |33       |\n",
            "|1025   |43       |\n",
            "|1127   |40       |\n",
            "|1084   |26       |\n",
            "|1139   |46       |\n",
            "|1143   |47       |\n",
            "|1016   |35       |\n",
            "|1005   |47       |\n",
            "|1133   |41       |\n",
            "|1068   |31       |\n",
            "|1031   |34       |\n",
            "|1051   |40       |\n",
            "|1064   |36       |\n",
            "|1034   |42       |\n",
            "|1030   |45       |\n",
            "|1019   |29       |\n",
            "|1135   |38       |\n",
            "|1148   |43       |\n",
            "|1056   |36       |\n",
            "|1085   |44       |\n",
            "+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encontre os 10 usuários mais ativos."
      ],
      "metadata": {
        "id": "ONHq4sAPgbKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = df_result.sort(F.desc('qtdAction')).limit(10)\n",
        "df_result.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX4eviSr86IH",
        "outputId": "6eba8279-2faa-4499-82b2-3e915f4cf839"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|user_id|qtdAction|\n",
            "+-------+---------+\n",
            "|1028   |54       |\n",
            "|1115   |54       |\n",
            "|1070   |54       |\n",
            "|1053   |52       |\n",
            "|1130   |51       |\n",
            "|1050   |50       |\n",
            "|1112   |50       |\n",
            "|1009   |50       |\n",
            "|1080   |49       |\n",
            "|1026   |48       |\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salve o resultado em um arquivo CSV."
      ],
      "metadata": {
        "id": "-Tdqc2DWgg7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"result/result_case_problem.csv\"\n",
        "df_result.write.mode(\"overwrite\").csv(output_path, header=True)\n",
        "\n",
        "print(\"DataFrame salvo como CSV em: {0}\".format(output_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZoLEN7C-OAH",
        "outputId": "4237e6e8-94d8-4a69-c50a-7639c1571838"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame salvo como CSV em: result/result_case_problem.csv\n"
          ]
        }
      ]
    }
  ]
}